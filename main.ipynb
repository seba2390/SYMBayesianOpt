{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-10T02:26:57.518834Z",
     "start_time": "2023-11-10T02:26:57.516743Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import *\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from numpy.random import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [],
   "source": [
    "class HyperParameters:\n",
    "    def __init__(self, \n",
    "                 num_params:int, \n",
    "                 limits: list[tuple[float,float]]=None, \n",
    "                 parameters: np.ndarray[float]=None):\n",
    "        if not isinstance(num_params, int):\n",
    "            raise TypeError('num_params must be an integer.')\n",
    "        if num_params <= 0:\n",
    "            raise ValueError('num_params must be greater than 0.')\n",
    "        if limits is not None:\n",
    "            if len(limits) != num_params:\n",
    "                raise ValueError('list of limits should be of length \"num_params\". ')\n",
    "        if parameters is not None:\n",
    "            if len(parameters) != num_params:\n",
    "                raise ValueError('When explicitly provided, the number of parameters should be equal to \"num_params\". ')\n",
    "        self.num_params = num_params\n",
    "        self.limits = limits\n",
    "        self.parameters = parameters\n",
    "        \n",
    "    def get_parameters(self):\n",
    "        if self.parameters is None:\n",
    "            raise RuntimeError(f' \"parameters\" attribute has not been set. ')\n",
    "        return self.parameters\n",
    "    \n",
    "    def set_parameters(self, parameters: np.ndarray[float]):\n",
    "        if len(parameters) != self.num_params:\n",
    "                raise ValueError('When explicitly provided, the number of parameters should be equal to \"num_params\". ')\n",
    "        self.parameters = parameters\n",
    "        \n",
    "    def set_random_parameters(self):\n",
    "        self.parameters = self.get_random_parameters()\n",
    "    \n",
    "    def get_random_parameters(self, distribution: str = 'uniform'):\n",
    "        if distribution == 'uniform':\n",
    "            if self.limits is not None:\n",
    "                self.parameters = np.array([uniform(low=limit[0], high=limit[1]) for limit in self.limits])\n",
    "            else:\n",
    "                self.parameters = np.array([uniform(low=-np.inf, high=np.inf) for _ in range(self.num_params)])\n",
    "            return self.get_parameters()\n",
    "        \n",
    "\n",
    "class CovarianceMatrix:\n",
    "    def __init__(self, kernel: Callable):\n",
    "        self.kernel = kernel\n",
    "        self.matrix = None\n",
    "        self.samples = []\n",
    "        \n",
    "    def update_matrix(self, new_samples: list[HyperParameters]):\n",
    "        # Updating samples\n",
    "        self.samples.extend(new_samples)\n",
    "        \n",
    "        # Filling matrix for first time\n",
    "        if self.matrix is None:\n",
    "            N = len(self.samples)\n",
    "            matrix = np.empty((N, N), dtype=float)\n",
    "            for i in range(N):\n",
    "                for j in range(i,N):\n",
    "                    matrix[i,j] = self.kernel(self.samples[i],self.samples[j])\n",
    "                    if i != j:\n",
    "                        matrix[j, i] = matrix[i, j]\n",
    "            self.matrix = matrix\n",
    "            \n",
    "        # Updating existing matrix \n",
    "        else:\n",
    "            N_new, N_old = len(new_samples), self.matrix.shape[0]\n",
    "            N_total = N_new + N_old\n",
    "            total_matrix = np.empty((N_total, N_total), dtype=float)\n",
    "            \n",
    "            # Updating total matrix w. old covariances\n",
    "            total_matrix[:N_old,:N_old] = self.matrix\n",
    "            \n",
    "            # Calculating covariances between old and new samples\n",
    "            for i in range(N_old):\n",
    "                for j in range(N_new):\n",
    "                    total_matrix[i, N_old + j] = self.kernel(self.samples[i], new_samples[j])\n",
    "                    total_matrix[N_old + j, i] = total_matrix[i, N_old + j]\n",
    "            \n",
    "            # Calculating covariances between new samples\n",
    "            for i in range(N_new):\n",
    "                for j in range(i, N_new):\n",
    "                    total_matrix[N_old + i, N_old + j] = self.kernel(new_samples[i], new_samples[j])\n",
    "                    if i != j:\n",
    "                        total_matrix[N_old + j, N_old + i] = total_matrix[N_old + i, N_old + j]\n",
    "                        \n",
    "            self.matrix = total_matrix\n",
    "                       \n",
    "    def get_matrix(self):\n",
    "        if self.matrix is None:\n",
    "            raise RuntimeError(f' \"matrix\" attribute has not yet been set. Method: \".update_matrix()\" must be called first. ')\n",
    "        return self.matrix\n",
    "    \n",
    "\n",
    "class GaussianProcess:\n",
    "    def __init__(self, kernel: Callable, optimization_function: Callable):\n",
    "        \n",
    "        self.optimization_function = optimization_function\n",
    "        self.kernel = kernel\n",
    "        self.covariance_matrix = CovarianceMatrix(kernel=self.kernel)\n",
    "        \n",
    "        # Define sample = x, then y=f(x) is sample_value \n",
    "        self.sample_values = []\n",
    "    \n",
    "    def add_samples(self, samples: list[HyperParameters]) -> None:\n",
    "        self.covariance_matrix.update_matrix(new_samples=samples)\n",
    "        for sample in samples:\n",
    "            self.sample_values.append(self.optimization_function(sample))\n",
    "    \n",
    "    def get_mean_and_variance(self, sample: HyperParameters) -> tuple[float, float]:\n",
    "        if self.covariance_matrix.matrix is None:\n",
    "            raise RuntimeError(f'No samples have been given yet - expecting call to method \".add_samples()\" first. ')\n",
    "        kernel_vector = np.array([self.kernel(old_sample, sample) for old_sample in self.covariance_matrix.samples])\n",
    "        inv_covar = np.linalg.inv(self.covariance_matrix.get_matrix())\n",
    "        mean = np.dot(kernel_vector, np.dot(inv_covar, np.array(self.sample_values)))\n",
    "        variance = self.kernel(sample,sample) - np.dot(kernel_vector, np.dot(inv_covar, np.array(kernel_vector)))\n",
    "        return mean, variance\n",
    "\n",
    "\n",
    "class BayesianOptimization:\n",
    "    def __init__(self, \n",
    "                 kernel: Callable, \n",
    "                 optimization_function: Callable,\n",
    "                 limits: list[tuple[float,float]]):\n",
    "        \n",
    "        self.limits = limits\n",
    "        self.kernel = kernel\n",
    "        self.optimization_function = optimization_function\n",
    "        self.gaussian_process = GaussianProcess(kernel=self.kernel, optimization_function=self.optimization_function)\n",
    "        self.best_sample, self.best_sample_value = None, None\n",
    "    \n",
    "    def acquisition_function(self, sample: HyperParameters) -> float:\n",
    "        \n",
    "        def probability_of_improvement(best_sample_value: float, mean: float, variance: float) -> float:\n",
    "            return norm.cdf((best_sample_value-mean)/np.sqrt(variance))\n",
    "        \n",
    "        mean, variance = self.gaussian_process.get_mean_and_variance(sample=sample)\n",
    "        return -probability_of_improvement(best_sample_value=self.best_sample_value, mean=mean, variance=variance)\n",
    "    \n",
    "    def optimize(self, N_warmup: int, N_optimize: int):\n",
    "        # Warm-up\n",
    "        samples = []\n",
    "        for random_sample in range(N_warmup):\n",
    "            params = HyperParameters(num_params=len(self.limits),limits=self.limits)\n",
    "            params.set_random_parameters()\n",
    "            samples.append(params)     \n",
    "        self.gaussian_process.add_samples(samples=samples)\n",
    "        best_idx = np.argmin(self.gaussian_process.sample_values)\n",
    "        self.best_sample, self.best_sample_value = samples[best_idx], self.gaussian_process.sample_values[best_idx]\n",
    "        \n",
    "        # Optimization        \n",
    "        def wrapper(x: np.ndarray[float]) -> float:\n",
    "            return self.acquisition_function(sample=HyperParameters(num_params=len(self.limits),\n",
    "                                                                    limits=self.limits,\n",
    "                                                                     parameters=x))\n",
    "        for optimization_sample in range(N_optimize):\n",
    "            # argmin_x \n",
    "            init = HyperParameters(num_params=len(self.limits),limits=self.limits)\n",
    "            init.set_random_parameters()\n",
    "            res = minimize(fun=wrapper, x0=init.get_parameters().flatten(), method='COBYLA', bounds=self.limits)\n",
    "            x_i = HyperParameters(num_params=len(self.limits), limits=self.limits, parameters=res.x)\n",
    "            \n",
    "            # Update samples, sample-values and covariance matrix.\n",
    "            self.gaussian_process.add_samples(samples=[x_i])\n",
    "            \n",
    "            # Update best values \n",
    "            best_idx = np.argmin(self.gaussian_process.sample_values)\n",
    "            self.best_sample, self.best_sample_value = self.gaussian_process.covariance_matrix.samples[best_idx], self.gaussian_process.sample_values[best_idx]\n",
    "        \n",
    "        return {'x': self.best_sample.get_parameters(),\n",
    "                'y': self.best_sample_value}\n",
    "            \n",
    "\n",
    "    \n",
    "def rbf_kernel(x1: HyperParameters, x2: HyperParameters, length_scale=1.0, sigma_f=1.0):\n",
    "    \"\"\"\n",
    "    Compute the Radial Basis Function (RBF) kernel between two d-dimensional vectors.\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute the squared Euclidean distance between the vectors\n",
    "    sqdist = np.sum((x1.get_parameters() - x2.get_parameters())**2)\n",
    "    \n",
    "    # Compute the RBF kernel\n",
    "    return sigma_f**2 * np.exp(-0.5 / length_scale**2 * sqdist)\n",
    "        \n",
    "\n",
    "# Treating variables as hyperparameters as an initial example example        \n",
    "def rosenbrock(x: HyperParameters) -> float:\n",
    "    x1, x2 = x.get_parameters(), x.get_parameters()[1]\n",
    "    return ((1 - x1) ** 2 + 100 * (x2-x1 ** 2) ** 2)[0]\n",
    "\n",
    "limits = [(-2,2), (-2,3)]\n",
    "opt = BayesianOptimization(kernel=rbf_kernel, \n",
    "                           optimization_function=rosenbrock,\n",
    "                           limits=limits)\n",
    "\n",
    "opt.optimize(N_warmup=5,N_optimize=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-10T02:26:57.536018Z",
     "start_time": "2023-11-10T02:26:57.532413Z"
    }
   },
   "id": "f908f6ee9cf25edd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
